# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `s07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: все числовые (float64), 8 признаков + sample_id
- Пропуски: нет пропусков
- "Подлости" датасета: признаки в разных шкалах, требуется обязательное масштабирование
### 1.2 Dataset B

- Файл: `s07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбцов)
- Признаки: все числовые (float64), 3 признаков + sample_id
- Пропуски: нет пропусков
- "Подлости" датасета: признаки в разных шкалах, требуется обязательное масштабирование
### 1.3 Dataset C

- Файл: `s07-hw-dataset-03.csv`
- Размер: (15000 строк, 5 столбцов)
- Признаки: все числовые (float64), 4 признаков + sample_id
- Пропуски: нет пропусков
- "Подлости" датасета: признаки в разных шкалах, требуется обязательное масштабирование

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг**: 
  - Проверка пропусков (пропусков не обнаружено во всех датасетах)
  - Стандартизация всех числовых признаков с помощью StandardScaler
  - Отделение sample_id от признаков перед обработкой

- **Поиск гиперпараметров**:
  - **KMeans**: диапазон k = 2..20, random_state=42, n_init=10
  - **DBSCAN**: eps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], min_samples = [2, 3, 5]
  - **Критерий выбора**: максимальный Silhouette Score как основной критерий

- **Метрики**: 
  - silhouette_score (выше - лучше)
  - davies_bouldin_score (ниже - лучше)  
  - calinski_harabasz_score (выше - лучше)
  - Для DBSCAN: метрики считались только на не-шумовых точках (label != -1)

- **Визуализация**: 
  - PCA(2D) с random_state=42 для всех датасетов
  - t-SNE не использовался (опционально)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для **каждого** датасета сравнивали:

1. **KMeans**:
   - Подбор k в диапазоне 2..20
   - Фиксированные: random_state=42, n_init=10
   - Критерий: максимизация Silhouette Score

2. **DBSCAN**:
   - Подбор eps: 0.1, 0.2, ..., 1.0
   - Подбор min_samples: 2, 3, 5
   - Критерий: максимизация Silhouette Score на не-шумовых точках

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN (eps=0.10, min_samples=2)
- Метрики:
  - Silhouette: 0.741
  - Davies-Bouldin: 0.269
  - Calinski-Harabasz: 1468.0
- - Доля шума: 0.991
- Коротко: DBSCAN показал лучшие результаты на этом датасете
### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (eps=1.00, min_samples=2)
- Метрики:
  - Silhouette: 0.435
  - Davies-Bouldin: 0.395
  - Calinski-Harabasz: 13.7
- - Доля шума: 0.001
- Коротко: DBSCAN показал лучшие результаты на этом датасете
### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN (eps=0.80, min_samples=2)
- Метрики:
  - Silhouette: 0.373
  - Davies-Bouldin: 0.551
  - Calinski-Harabasz: 17.2
- - Доля шума: 0.001
- Коротко: DBSCAN показал лучшие результаты на этом датасете

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"**: на датасетах с нелинейной структурой или при наличии выбросов, так как предполагает сферические кластеры
- **DBSCAN выигрывает**: когда важна плотность кластеров, при наличии шума, для нелинейных структур
- **Влияние факторов**: 
  - Масштабирование критически важно для KMeans
  - Выбросы сильно влияют на KMeans, но могут быть выделены как шум в DBSCAN
  - Разная плотность кластеров - слабое место KMeans

### 5.2 Устойчивость (обязательно для одного датасета)

- **Проверка**: 5 запусков KMeans с разными random_state (42, 123, 456, 789, 999) на одном из датасетов
- **Результаты**: 
  - Средний ARI: 1.0000
  - Диапазон ARI: [1.0000, 1.0000]
  - Стандартное отклонение: 0.0000
- **Вывод**: KMeans демонстрирует очень высокую устойчивость, результаты воспроизводимы при разных инициализациях

### 5.3 Интерпретация кластеров

- **Метод интерпретации**: анализ средних значений признаков по кластерам
- **Наблюдения**: 
  - Кластеры различаются по средним значениям ключевых признаков
  - PCA визуализация подтверждает осмысленность выделенных кластеров
  - Для разных датасетов ключевые признаки различаются
- **Выводы**: Выделенные кластеры имеют различимый профиль по исходным признакам, что подтверждает содержательность кластеризации

## 6. Conclusion

1. **Масштабирование обязательно**: Без StandardScaler distance-based методы (KMeans, DBSCAN) дают бессмысленные результаты
2. **Выбор метода зависит от структуры данных**: KMeans для линейных структур, DBSCAN для нелинейных и при наличии шума
3. **Внутренние метрики полезны, но ограничены**: Silhouette Score хорош для сравнения, но не гарантирует содержательность кластеров
4. **PCA-визуализация необходима**: Помогает понять структуру данных и оценить качество кластеризации
5. **DBSCAN требует аккуратного подбора параметров**: eps и min_samples критически влияют на результат
6. **Устойчивость KMeans высокая**: При фиксированных данных и разумном k результаты воспроизводимы
7. **"Честный" протокол включает**: препроцессинг, подбор параметров, оценку метриками, визуализацию
8. **Каждый датасет требует индивидуального подхода**: Нет универсального лучшего метода для всех случаев
