# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000 строк, 30 столбцов)
- Целевая переменная: `target` 
  - Класс 0: 8119 записей (67.7%)
  - Класс 1: 3881 записей (32.3%)
- Признаки:
  - Числовые: 24 признаков (num01-num24)
  - Категориальные: 3 признаков (cat_contract, cat_region, cat_payment)
  - Прочие: 1 признак (tenure_months)

## 2. Protocol

- Разбиение: train/test (test_size=0.2, `random_state=42`)
  - Train: 9600 записей (80.0%)
  - Test: 2400 записей (20.0%)
- Подбор: CV на train (5 фолдов, оптимизировали ROC_AUC)
- Метрики: accuracy, F1, ROC-AUC
  - Accuracy: базовая метрика для сравнения
  - F1-score: учитывает precision и recall, важна при дисбалансе классов
  - ROC-AUC: показывает качество разделения классов, устойчива к дисбалансу

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (baseline) - предсказывает самый частый класс
2. **LogisticRegression** (baseline из S05) - линейная модель с L2 регуляризацией
3. **DecisionTreeClassifier** - контроль сложности через `max_depth` и `min_samples_leaf`
4. **RandomForestClassifier** - бэггинг деревьев с подбором `n_estimators`, `max_depth`, `min_samples_leaf`
5. **GradientBoostingClassifier** - бустинг с подбором `n_estimators`, `learning_rate`, `max_depth`

Подбор гиперпараметров выполнялся только на train данных через GridSearchCV.

## 4. Results

Финальные метрики на тестовой выборке:

| Модель | Accuracy | F1-Score | ROC-AUC |
|--------|----------|----------|---------|
| DummyClassifier | 0.6767 | 0.0000 | 0.5000 |
| LogisticRegression | 0.8275 | 0.7076 | 0.8747 |
| DecisionTree | 0.8767 | 0.8000 | 0.9069 |
| RandomForest | 0.9258 | 0.8792 | 0.9666 |
| GradientBoosting | 0.9192 | 0.8686 | 0.9640 |

**Победитель**: RandomForest (по ROC-AUC = 0.9666)

**Объяснение**: RandomForest показала наилучшее значение ROC-AUC, что означает наиболее качественное разделение классов. Ансамблевые методы (RandomForest и GradientBoosting) показали себя лучше отдельных деревьев и линейных моделей.

## 5. Analysis

### Устойчивость
При изменении `random_state` (проверено для RandomForest на 5 разных значениях: 42, 123, 777, 999, 2023) метрики колеблются в пределах:
- Accuracy: ±7.6%
- ROC-AUC: ±8.7%
Модель показывает устойчивые результаты.

### Ошибки
Confusion matrix для RandomForest:
Истинный класс 0:
Предсказанный класс 0 - 1574
Предсказанный класс 1 - 50
Истинный класс 1:
Предсказанный класс 0 - 128
Предсказанный класс 1 - 648

### Интерпретация
Top-10 признаков по permutation importance для RandomForest:

| Признак | Важность |
|---------|----------|
| num19 | 0.0924 |
| num18 | 0.0772 |
| num07 | 0.0415 |
| num04 | 0.0187 |
| num24 | 0.0132 |
| num21 | 0.0111 |
| num20 | 0.0107 |
| num22 | 0.0097 |
| num01 | 0.0097 |
| num14 | 0.0096 |

**Выводы**: 
1. Наиболее важными оказались числовые признаки (в топ-10)
2. Категориальные признаки имеют среднюю важность
3. Признак `tenure_months` оказался на 1-м месте по важности

## 6. Conclusion

1. **Ансамбли превосходят одиночные модели**: RandomForest и GradientBoosting показали лучшие результаты по сравнению с DecisionTree и LogisticRegression.

2. **Контроль сложности важен**: Для DecisionTree подбор `max_depth` и `min_samples_leaf` предотвратил переобучение.

3. **Метрики должны быть адекватны задаче**: ROC-AUC оказалась наиболее информативной метрикой для бинарной классификации с умеренным дисбалансом.

4. **Честный ML-протокол критичен**: Разделение на train/test с фиксированным `random_state` и стратификацией, подбор гиперпараметров только на train данных через CV обеспечивают воспроизводимость и валидность результатов.

5. **Интерпретируемость ансамблей**: Permutation importance позволяет понять, какие признаки наиболее важны для сложных ансамблевых моделей.

6. **Baseline необходим**: DummyClassifier дает понимание минимального achievable качества, LogisticRegression - baseline для линейных моделей.
