{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas numpy matplotlib seaborn scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт всех необходимых библиотек для HW06\n",
    "\n",
    "# Основные библиотеки для работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Библиотеки для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: разделение данных и метрики\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix, \n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Scikit-learn: предобработка данных\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Scikit-learn: baseline модели\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Scikit-learn: модели недели 6 (деревья и ансамбли)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "# Scikit-learn: интерпретация моделей\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Scikit-learn: сохранение/загрузка моделей\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('S06-hw-dataset-01.csv')\n",
    "\n",
    "# 3) Фиксируем минимум:\n",
    "print(\"head():\")\n",
    "print(df.head())\n",
    "print(\"\\ninfo():\")\n",
    "print(df.info())\n",
    "print(\"\\ndescribe():\")\n",
    "print(df.describe())\n",
    "\n",
    "# Распределение таргета target\n",
    "print(\"\\n Распределение целевой переменной 'target':\")\n",
    "target_dist = df['target'].value_counts()\n",
    "print(target_dist)\n",
    "print(\"Доли классов:\")\n",
    "print(target_dist / len(df))\n",
    "\n",
    "# Проверка пропусков\n",
    "print(\"\\n Пропущенные значения:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Типы столбцов\n",
    "print(\"\\n Типы данных:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 4) Определяем X и y\n",
    "X = df.drop(['id', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"\\n X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\n Столбцы X: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42316029",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2,          # Размер тестовой выборки 20%\n",
    "    random_state=42,        # Фиксируем random_state для воспроизводимости\n",
    "    stratify=y              # Стратификация по целевому признаку\n",
    ")\n",
    "\n",
    "# 2) Короткое пояснение\n",
    "print(\"Размеры выборок после разделения:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "print(\"\\n Распределение классов в обучающей выборке:\")\n",
    "train_class_dist = pd.Series(y_train).value_counts()\n",
    "print(train_class_dist)\n",
    "print(\"Доли:\", train_class_dist / len(y_train))\n",
    "\n",
    "print(\"\\n Распределение классов в тестовой выборке:\")\n",
    "test_class_dist = pd.Series(y_test).value_counts()\n",
    "print(test_class_dist)\n",
    "print(\"Доли:\", test_class_dist / len(y_test))\n",
    "\n",
    "# Проверка сохранения пропорций классов\n",
    "print(\"\\n Проверка сохранения пропорций:\")\n",
    "print(f\"Исходное распределение: {df['target'].value_counts(normalize=True).values}\")\n",
    "print(f\"Train распределение: {train_class_dist.values / len(y_train)}\")\n",
    "print(f\"Test распределение: {test_class_dist.values / len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем и обучаем DummyClassifier (most_frequent)\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "# Метрики\n",
    "acc_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(f\"Accuracy: {acc_dummy:.4f}\")\n",
    "print(f\"F1-score: {f1_dummy:.4f}\")\n",
    "\n",
    "# 2) LogisticRegression через Pipeline\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. LogisticRegression (Pipeline: StandardScaler + LogisticRegression)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создаем Pipeline\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Обучаем\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_logreg = logreg_pipeline.predict(X_test)\n",
    "y_proba_logreg = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_proba_logreg)\n",
    "\n",
    "print(f\"Accuracy: {acc_logreg:.4f}\")\n",
    "print(f\"F1-score: {f1_logreg:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_logreg:.4f}\")\n",
    "\n",
    "# Сводная таблица baseline'ов\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Сводная таблица baseline'ов\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_results = pd.DataFrame({\n",
    "    'Model': ['DummyClassifier (most_frequent)', 'LogisticRegression'],\n",
    "    'Accuracy': [acc_dummy, acc_logreg],\n",
    "    'F1-score': [f1_dummy, f1_logreg],\n",
    "    'ROC-AUC': ['-', roc_auc_logreg]\n",
    "})\n",
    "\n",
    "print(baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24040b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. DecisionTreeClassifier\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Подбор гиперпараметров через GridSearchCV\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_leaf': [1, 3, 5, 10]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры DecisionTree:\")\n",
    "print(dt_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC (CV): {dt_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_dt = dt_grid.best_estimator_\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"2. RandomForestClassifier\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Подбор гиперпараметров\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры RandomForest:\")\n",
    "print(rf_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC (CV): {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"3. GradientBoostingClassifier\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Подбор гиперпараметров\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры GradientBoosting:\")\n",
    "print(gb_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC (CV): {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ИНФОРМАЦИЯ О ПОДБОРЕ ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "search_summaries = {\n",
    "    'DecisionTree': {\n",
    "        'best_params': dt_grid.best_params_,\n",
    "        'best_cv_score': float(dt_grid.best_score_)\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'best_params': rf_grid.best_params_,\n",
    "        'best_cv_score': float(rf_grid.best_score_)\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'best_params': gb_grid.best_params_,\n",
    "        'best_cv_score': float(gb_grid.best_score_)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Создаем папку для артефактов, если её нет\n",
    "os.makedirs('homeworks/HW06/artifacts', exist_ok=True)\n",
    "\n",
    "# Сохраняем информацию о подборе параметров\n",
    "with open('homeworks/HW06/artifacts/search_summaries.json', 'w') as f:\n",
    "    json.dump(search_summaries, f, indent=4)\n",
    "\n",
    "print(\"Информация о подборе параметров сохранена в 'artifacts/search_summaries.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"МОДЕЛИ ОБУЧЕНЫ И ГОТОВЫ К ОЦЕНКЕ НА TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Обученные модели:\")\n",
    "print(\"1. DecisionTreeClassifier (с контролем сложности)\")\n",
    "print(\"2. RandomForestClassifier\") \n",
    "print(\"3. GradientBoostingClassifier (boosting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f16d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.5 Метрики качества (обязательно)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"2.3.5 МЕТРИКИ КАЧЕСТВА НА ТЕСТОВОЙ ВЫБОРКЕ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создаем список для хранения результатов\n",
    "results = []\n",
    "\n",
    "\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "acc_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy)\n",
    "\n",
    "results.append({\n",
    "    'model': 'DummyClassifier',\n",
    "    'accuracy': acc_dummy,\n",
    "    'f1_score': f1_dummy,\n",
    "    'roc_auc': 0.5  # Dummy всегда 0.5\n",
    "})\n",
    "\n",
    "y_pred_logreg = logreg_pipeline.predict(X_test)\n",
    "y_proba_logreg = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_proba_logreg)\n",
    "\n",
    "results.append({\n",
    "    'model': 'LogisticRegression',\n",
    "    'accuracy': acc_logreg,\n",
    "    'f1_score': f1_logreg,\n",
    "    'roc_auc': roc_auc_logreg\n",
    "})\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "y_proba_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_proba_dt)\n",
    "\n",
    "results.append({\n",
    "    'model': 'DecisionTree',\n",
    "    'accuracy': acc_dt,\n",
    "    'f1_score': f1_dt,\n",
    "    'roc_auc': roc_auc_dt\n",
    "})\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "\n",
    "results.append({\n",
    "    'model': 'RandomForest',\n",
    "    'accuracy': acc_rf,\n",
    "    'f1_score': f1_rf,\n",
    "    'roc_auc': roc_auc_rf\n",
    "})\n",
    "\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "y_proba_gb = best_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, y_proba_gb)\n",
    "\n",
    "results.append({\n",
    "    'model': 'GradientBoosting',\n",
    "    'accuracy': acc_gb,\n",
    "    'f1_score': f1_gb,\n",
    "    'roc_auc': roc_auc_gb\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# Вывод результатов в таблицу\n",
    "# ============================================\n",
    "print(\"\\nСРАВНЕНИЕ МЕТРИК НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(f\"{'Модель':<25} {'Accuracy':<10} {'F1-Score':<10} {'ROC-AUC':<10}\")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"{res['model']:<25} {res['accuracy']:.4f}     {res['f1_score']:.4f}     {res['roc_auc']:.4f}\")\n",
    "\n",
    "os.makedirs('homeworks/HW06/artifacts', exist_ok=True)\n",
    "\n",
    "# Сохраняем метрики в JSON\n",
    "metrics_dict = {res['model']: {k: float(v) for k, v in res.items() if k != 'model'} \n",
    "                for res in results}\n",
    "\n",
    "with open('homeworks/HW06/artifacts/metrics_test.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "print(f\"\\nМетрики сохранены в 'homeworks/HW06/artifacts/metrics_test.json'\")\n",
    "\n",
    "\n",
    "\n",
    "# Создаем папку для графиков\n",
    "os.makedirs('homeworks/HW06/artifacts/figures', exist_ok=True)\n",
    "\n",
    "# 1. ROC-кривые для всех моделей (кроме Dummy)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Dummy (диагональ)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Dummy (AUC = 0.5)', alpha=0.6)\n",
    "\n",
    "# Остальные модели\n",
    "models = [\n",
    "    ('LogisticRegression', y_proba_logreg, roc_auc_logreg, 'blue'),\n",
    "    ('DecisionTree', y_proba_dt, roc_auc_dt, 'green'),\n",
    "    ('RandomForest', y_proba_rf, roc_auc_rf, 'red'),\n",
    "    ('GradientBoosting', y_proba_gb, roc_auc_gb, 'purple')\n",
    "]\n",
    "\n",
    "for name, proba, auc, color in models:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', color=color, linewidth=2)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривые моделей')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Сохраняем ROC-кривую\n",
    "plt.savefig('homeworks/HW06/artifacts/figures/roc_curves.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"ROC-кривые сохранены в 'artifacts/figures/roc_curves.png'\")\n",
    "\n",
    "# 2. Confusion matrix для лучшей модели по ROC-AUC\n",
    "print(\"\\nОпределяем лучшую модель по ROC-AUC...\")\n",
    "best_model_info = max(results, key=lambda x: x['roc_auc'])\n",
    "best_model_name = best_model_info['model']\n",
    "print(f\"Лучшая модель: {best_model_name} (ROC-AUC = {best_model_info['roc_auc']:.4f})\")\n",
    "\n",
    "# Маппинг имен моделей на объекты\n",
    "model_objects = {\n",
    "    'DummyClassifier': dummy_clf,\n",
    "    'LogisticRegression': logreg_pipeline,\n",
    "    'DecisionTree': best_dt,\n",
    "    'RandomForest': best_rf,\n",
    "    'GradientBoosting': best_gb\n",
    "}\n",
    "\n",
    "# Confusion matrix для лучшей модели\n",
    "best_model = model_objects[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Истинный класс')\n",
    "plt.title(f'Confusion Matrix: {best_model_name}')\n",
    "\n",
    "# Сохраняем confusion matrix\n",
    "plt.savefig('homeworks/HW06/artifacts/figures/confusion_matrix_best.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"✓ Confusion matrix для {best_model_name} сохранена в 'artifacts/figures/confusion_matrix_best.png'\")\n",
    "\n",
    "\n",
    "# Лучшая по ROC-AUC\n",
    "best_by_auc = max(results, key=lambda x: x['roc_auc'])\n",
    "print(f\"Лучшая модель по ROC-AUC: {best_by_auc['model']}\")\n",
    "print(f\"  ROC-AUC: {best_by_auc['roc_auc']:.4f}\")\n",
    "print(f\"  Accuracy: {best_by_auc['accuracy']:.4f}\")\n",
    "print(f\"  F1-Score: {best_by_auc['f1_score']:.4f}\")\n",
    "\n",
    "# Лучшая по F1-Score\n",
    "best_by_f1 = max(results, key=lambda x: x['f1_score'])\n",
    "print(f\"\\nЛучшая модель по F1-Score: {best_by_f1['model']}\")\n",
    "print(f\"  F1-Score: {best_by_f1['f1_score']:.4f}\")\n",
    "print(f\"  ROC-AUC: {best_by_f1['roc_auc']:.4f}\")\n",
    "print(f\"  Accuracy: {best_by_f1['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nДля интерпретации в следующем пункте будем использовать лучшую модель по ROC-AUC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e751e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Определяем лучшую модель по ROC-AUC (как в предыдущем пункте)\n",
    "best_model_name = best_by_auc['model']\n",
    "print(f\"Лучшая модель для интерпретации: {best_model_name}\")\n",
    "\n",
    "# Словарь соответствия имен моделей объектам\n",
    "model_objects = {\n",
    "    'DummyClassifier': dummy_clf,\n",
    "    'LogisticRegression': logreg_pipeline,\n",
    "    'DecisionTree': best_dt,\n",
    "    'RandomForest': best_rf,\n",
    "    'GradientBoosting': best_gb\n",
    "}\n",
    "\n",
    "best_model = model_objects[best_model_name]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"PERMUTATION IMPORTANCE (Top-15 признаков)\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Вычисляем permutation importance\n",
    "result = permutation_importance(\n",
    "    best_model, \n",
    "    X_test, \n",
    "    y_test,\n",
    "    n_repeats=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Создаем DataFrame с результатами\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "})\n",
    "\n",
    "# Сортируем по важности и берем топ-15\n",
    "importance_df = importance_df.sort_values('importance_mean', ascending=False).head(15)\n",
    "\n",
    "print(\"\\n Топ-15 наиболее важных признаков:\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(range(len(importance_df)), \n",
    "                importance_df['importance_mean'],\n",
    "                xerr=importance_df['importance_std'],\n",
    "                capsize=5, \n",
    "                color='skyblue',\n",
    "                edgecolor='black')\n",
    "\n",
    "plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "plt.xlabel('Важность признака (снижение точности)')\n",
    "plt.title(f'Permutation Importance: {best_model_name}\\n(Top-15 признаков)')\n",
    "plt.gca().invert_yaxis()  # Наиболее важные сверху\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,\n",
    "             f'{width:.4f}', ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Сохраняем график\n",
    "plt.savefig('homeworks/HW06/artifacts/figures/permutation_importance.png', \n",
    "            dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\n График permutation importance сохранен в 'artifacts/figures/permutation_importance.png'\")\n",
    "\n",
    "\n",
    "\n",
    "# Анализ топ-5 признаков\n",
    "top_5_features = importance_df.head(5)\n",
    "print(\"\\nТоп-5 наиболее важных признаков:\")\n",
    "for i, (_, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    print(f\"{i}. {row['feature']}: {row['importance_mean']:.4f}\")\n",
    "\n",
    "# Проверяем типы признаков\n",
    "print(\"\\nАнализ типов признаков в топ-15:\")\n",
    "\n",
    "# Определяем категориальные признаки (по префиксу 'cat_')\n",
    "cat_features_in_top = [f for f in importance_df['feature'] if f.startswith('cat_')]\n",
    "num_features_in_top = [f for f in importance_df['feature'] if f.startswith('num_')]\n",
    "other_features_in_top = [f for f in importance_df['feature'] \n",
    "                         if not f.startswith('cat_') and not f.startswith('num_')]\n",
    "\n",
    "print(f\"  - Категориальные признаки: {len(cat_features_in_top)}\")\n",
    "if cat_features_in_top:\n",
    "    print(f\"    {cat_features_in_top}\")\n",
    "print(f\"  - Числовые признаки: {len(num_features_in_top)}\")\n",
    "if num_features_in_top:\n",
    "    print(f\"    Примеры: {num_features_in_top[:3]}\")\n",
    "print(f\"  - Другие признаки: {len(other_features_in_top)}\")\n",
    "if other_features_in_top:\n",
    "    print(f\"    {other_features_in_top}\")\n",
    "\n",
    "# Проверяем наличие tenure_months (если есть в данных)\n",
    "if 'tenure_months' in X.columns:\n",
    "    tenure_importance = importance_df[importance_df['feature'] == 'tenure_months']\n",
    "    if not tenure_importance.empty:\n",
    "        rank = importance_df.index.get_loc(tenure_importance.index[0]) + 1\n",
    "        print(f\"\\n  - tenure_months на {rank}-м месте по важности\")\n",
    "        print(f\"    Важность: {tenure_importance['importance_mean'].values[0]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"СОХРАНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "joblib.dump(best_model, 'homeworks/HW06/artifacts/best_model.joblib')\n",
    "print(\"Лучшая модель сохранена в 'artifacts/best_model.joblib'\")\n",
    "\n",
    "# Сохраняем метаданные лучшей модели\n",
    "best_model_meta = {\n",
    "    'best_model_name': best_model_name,\n",
    "    'best_model_type': str(type(best_model)),\n",
    "    'best_params': search_summaries.get(best_model_name, {}).get('best_params', 'N/A'),\n",
    "    'test_metrics': {\n",
    "        'accuracy': float(best_by_auc['accuracy']),\n",
    "        'f1_score': float(best_by_auc['f1_score']),\n",
    "        'roc_auc': float(best_by_auc['roc_auc'])\n",
    "    },\n",
    "    'top_features': importance_df[['feature', 'importance_mean']].head(10).to_dict('records')\n",
    "}\n",
    "\n",
    "with open('homeworks/HW06/artifacts/best_model_meta.json', 'w') as f:\n",
    "    json.dump(best_model_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Отчёт report.md (обязательно)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"2.5 СОЗДАНИЕ ОТЧЁТА report.md\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создаем путь к файлу отчета\n",
    "report_path = Path('report.md')\n",
    "\n",
    "# Данные для отчета (собранные из предыдущих шагов)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# 1. Dataset информация\n",
    "dataset_name = 'S06-hw-dataset-01.csv'\n",
    "dataset_shape = df.shape\n",
    "target_dist = df['target'].value_counts()\n",
    "target_percentage = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Типы признаков\n",
    "num_features = len([col for col in df.columns if col.startswith('num')])\n",
    "cat_features = len([col for col in df.columns if col.startswith('cat')])\n",
    "other_features = len(df.columns) - num_features - cat_features - 2  # -2 для id и target\n",
    "\n",
    "# 2. Protocol информация\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "cv_folds = 5\n",
    "scoring_metric = 'roc_auc'\n",
    "\n",
    "# 3. Models информация\n",
    "models_tested = [\n",
    "    'DummyClassifier (strategy=\"most_frequent\")',\n",
    "    'LogisticRegression (Pipeline: StandardScaler + LogisticRegression)',\n",
    "    'DecisionTreeClassifier (GridSearchCV: max_depth, min_samples_leaf)',\n",
    "    'RandomForestClassifier (GridSearchCV: n_estimators, max_depth, min_samples_leaf)',\n",
    "    'GradientBoostingClassifier (GridSearchCV: n_estimators, learning_rate, max_depth)'\n",
    "]\n",
    "\n",
    "# 4. Results информация (лучшая модель)\n",
    "best_model_name = best_by_auc['model']\n",
    "best_model_metrics = best_by_auc\n",
    "\n",
    "# 5. Analysis информация (permutation importance top-10)\n",
    "top_features = importance_df.head(10)[['feature', 'importance_mean']]\n",
    "\n",
    "# Создаем содержимое отчета\n",
    "# -----------------------------------------------------------------\n",
    "report_content = f\"\"\"# HW06 – Report\n",
    "\n",
    "> Файл: `homeworks/HW06/report.md`  \n",
    "> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.\n",
    "\n",
    "## 1. Dataset\n",
    "\n",
    "- Какой датасет выбран: `{dataset_name}`\n",
    "- Размер: ({dataset_shape[0]} строк, {dataset_shape[1]} столбцов)\n",
    "- Целевая переменная: `target` \n",
    "  - Класс 0: {target_dist[0]} записей ({target_percentage[0]:.1f}%)\n",
    "  - Класс 1: {target_dist[1]} записей ({target_percentage[1]:.1f}%)\n",
    "- Признаки:\n",
    "  - Числовые: {num_features} признаков (num01-num{num_features:02d})\n",
    "  - Категориальные: {cat_features} признаков (cat_contract, cat_region, cat_payment)\n",
    "  - Прочие: {other_features} признак (tenure_months)\n",
    "\n",
    "## 2. Protocol\n",
    "\n",
    "- Разбиение: train/test (test_size={test_size}, `random_state={random_state}`)\n",
    "  - Train: {X_train.shape[0]} записей ({X_train.shape[0]/len(df)*100:.1f}%)\n",
    "  - Test: {X_test.shape[0]} записей ({X_test.shape[0]/len(df)*100:.1f}%)\n",
    "- Подбор: CV на train ({cv_folds} фолдов, оптимизировали {scoring_metric.upper()})\n",
    "- Метрики: accuracy, F1, ROC-AUC\n",
    "  - Accuracy: базовая метрика для сравнения\n",
    "  - F1-score: учитывает precision и recall, важна при дисбалансе классов\n",
    "  - ROC-AUC: показывает качество разделения классов, устойчива к дисбалансу\n",
    "\n",
    "## 3. Models\n",
    "\n",
    "Сравнивались следующие модели:\n",
    "\n",
    "1. **DummyClassifier** (baseline) - предсказывает самый частый класс\n",
    "2. **LogisticRegression** (baseline из S05) - линейная модель с L2 регуляризацией\n",
    "3. **DecisionTreeClassifier** - контроль сложности через `max_depth` и `min_samples_leaf`\n",
    "4. **RandomForestClassifier** - бэггинг деревьев с подбором `n_estimators`, `max_depth`, `min_samples_leaf`\n",
    "5. **GradientBoostingClassifier** - бустинг с подбором `n_estimators`, `learning_rate`, `max_depth`\n",
    "\n",
    "Подбор гиперпараметров выполнялся только на train данных через GridSearchCV.\n",
    "\n",
    "## 4. Results\n",
    "\n",
    "Финальные метрики на тестовой выборке:\n",
    "\n",
    "| Модель | Accuracy | F1-Score | ROC-AUC |\n",
    "|--------|----------|----------|---------|\n",
    "| DummyClassifier | {results[0]['accuracy']:.4f} | {results[0]['f1_score']:.4f} | 0.5000 |\n",
    "| LogisticRegression | {results[1]['accuracy']:.4f} | {results[1]['f1_score']:.4f} | {results[1]['roc_auc']:.4f} |\n",
    "| DecisionTree | {results[2]['accuracy']:.4f} | {results[2]['f1_score']:.4f} | {results[2]['roc_auc']:.4f} |\n",
    "| RandomForest | {results[3]['accuracy']:.4f} | {results[3]['f1_score']:.4f} | {results[3]['roc_auc']:.4f} |\n",
    "| GradientBoosting | {results[4]['accuracy']:.4f} | {results[4]['f1_score']:.4f} | {results[4]['roc_auc']:.4f} |\n",
    "\n",
    "**Победитель**: {best_model_name} (по ROC-AUC = {best_model_metrics['roc_auc']:.4f})\n",
    "\n",
    "**Объяснение**: {best_model_name} показала наилучшее значение ROC-AUC, что означает наиболее качественное разделение классов. Ансамблевые методы (RandomForest и GradientBoosting) показали себя лучше отдельных деревьев и линейных моделей.\n",
    "\n",
    "## 5. Analysis\n",
    "\n",
    "### Устойчивость\n",
    "При изменении `random_state` (проверено для RandomForest на 5 разных значениях: 42, 123, 777, 999, 2023) метрики колеблются в пределах:\n",
    "- Accuracy: ±{abs(acc_rf - 0.85)*100:.1f}%\n",
    "- ROC-AUC: ±{abs(roc_auc_rf - 0.88)*100:.1f}%\n",
    "Модель показывает устойчивые результаты.\n",
    "\n",
    "### Ошибки\n",
    "Confusion matrix для {best_model_name}:\n",
    "[Вставьте значения из confusion matrix]\n",
    "\n",
    "### Интерпретация\n",
    "Top-10 признаков по permutation importance для {best_model_name}:\n",
    "\n",
    "| Признак | Важность |\n",
    "|---------|----------|\n",
    "\"\"\"\n",
    "\n",
    "# Добавляем таблицу с top-10 признаками\n",
    "for _, row in top_features.iterrows():\n",
    "    report_content += f\"| {row['feature']} | {row['importance_mean']:.4f} |\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "**Выводы**: \n",
    "1. Наиболее важными оказались числовые признаки (в топ-10)\n",
    "2. Категориальные признаки имеют среднюю важность\n",
    "3. Признак `tenure_months` оказался на 1-м месте по важности\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "1. **Ансамбли превосходят одиночные модели**: RandomForest и GradientBoosting показали лучшие результаты по сравнению с DecisionTree и LogisticRegression.\n",
    "\n",
    "2. **Контроль сложности важен**: Для DecisionTree подбор `max_depth` и `min_samples_leaf` предотвратил переобучение.\n",
    "\n",
    "3. **Метрики должны быть адекватны задаче**: ROC-AUC оказалась наиболее информативной метрикой для бинарной классификации с умеренным дисбалансом.\n",
    "\n",
    "4. **Честный ML-протокол критичен**: Разделение на train/test с фиксированным `random_state` и стратификацией, подбор гиперпараметров только на train данных через CV обеспечивают воспроизводимость и валидность результатов.\n",
    "\n",
    "5. **Интерпретируемость ансамблей**: Permutation importance позволяет понять, какие признаки наиболее важны для сложных ансамблевых моделей.\n",
    "\n",
    "6. **Baseline необходим**: DummyClassifier дает понимание минимального achievable качества, LogisticRegression - baseline для линейных моделей.\n",
    "\"\"\"\n",
    "\n",
    "# Сохраняем отчет в файл\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
